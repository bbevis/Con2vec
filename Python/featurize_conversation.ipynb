{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/xehu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from team_comm_tools import FeatureBuilder\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_convo_df = pd.read_csv('../Output/super_May22/Merged_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, get the cleaned up turns\n",
    "merged_convo_df = merged_convo_df[[\"SourceFile\", \"Speaker\", \"Backchannel\", \"Overlap\", \"Turn\", \"Contested\", \"Sent\", \"Turn Start\", \"Turn End\", \"Sentiment\", \"word_count\"]].drop_duplicates()\n",
    "\n",
    "# separate cases where the \"Speaker\" is \"Both\" or \"Contested\" = 1 into another df; let's handle this separately\n",
    "contested_df = merged_convo_df[(merged_convo_df[\"Speaker\"] == \"Both\") | (merged_convo_df[\"Contested\"] == 1)].reset_index(drop=True)\n",
    "non_contested_df = merged_convo_df[(merged_convo_df[\"Speaker\"] != \"Both\") & (merged_convo_df[\"Contested\"] == 0)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Featurization...\n",
      "Confirmed that data has conversation_id: SourceFile, speaker_id: Speaker and message: Sent columns!\n",
      "Chat Level Features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 12/17 [00:25<00:16,  3.39s/it]"
     ]
    }
   ],
   "source": [
    "feature_builder = FeatureBuilder(\n",
    "        input_df = non_contested_df,\n",
    "        conversation_id_col = \"SourceFile\",\n",
    "        speaker_id_col = \"Speaker\",\n",
    "        message_col = \"Sent\",\n",
    "        timestamp_col = [\"Turn Start\", \"Turn End\"],\n",
    "        vector_directory = \"../Output/super_May22/convo_featurization/vector_data/\",\n",
    "        output_file_path_chat_level = \"../Output/super_May22/convo_featurization/may_super_turn_level.csv\",\n",
    "\t\toutput_file_path_user_level = \"../Output/super_May22/convo_featurization/may_super_speaker_level.csv\",\n",
    "\t\toutput_file_path_conv_level = \"../Output/super_May22/convo_featurization/may_super_conversation_level.csv\",\n",
    "    \tcustom_features = [\n",
    "\t\t\t\"(BERT) Mimicry\",\n",
    "\t\t\t\"Moving Mimicry\",\n",
    "\t\t\t\"Forward Flow\",\n",
    "\t\t\t\"Discursive Diversity\"])\n",
    "feature_builder.featurize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turn_output = pd.read_csv(\"../Output/super_May22/convo_featurization/output/turn/may_super_turn_level.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turn_output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tpm_virtualenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
